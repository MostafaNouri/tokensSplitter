# tokensSplitter

this project get persian and english words from a file. then there are some merged words that created unreadable sentences.
by main.py file it get merged words and main words then process mregred words with MAX LENGTH algorithm. in the end the output will get 
readable words or Error in "output/enSentences.txt" and "output/faSentences.txt" line by line.
